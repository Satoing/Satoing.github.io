---
title: "【科普向】视频编解码"
date: 2025-05-05
categories: ["科普向", "音视频开发"]
tags: ["音视频"]
---

玩nas经常听到视频编码、解码、转码这些词，然后又和CPU、显卡关联，有点让人摸不着头脑。

下面这篇文章对一些关键概念解释的比较清楚：

[科普向:一文搞懂什么是串流、硬解、转码，你的nas真的需要硬解吗？](https://post.smzdm.com/p/alldz028/)

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746416314180-8e76cafd-8a05-4b67-a66f-4966fdc52329.png)

但是里面还是有很多不严谨的地方，

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746416395493-8300fca4-e456-4789-acda-4c77e8c5149d.png)

正好这里又涉及到码率（容易和帧率混淆）等一知半解的概念，不妨在这篇文章中一起探索探索。

## 一、图像和视频
### 1.1 图像
图像由像素组成，彩色图像的每个像素一般包含RGB三个通道（也有A通道表示透明度）。每个通道通常的位深是8bit，即每个通道能表示256中颜色，三个通道总共能表示1677万种颜色。

图像的清晰度可以由分辨率来衡量。日常中熟悉的分辨率有<font style="color:rgb(53, 53, 53);"> 360P（640x360）、720P（1280x720）、1080P（1920x1080）、4K（3840x2160）、8K（7680x4320）。</font>

<font style="color:rgb(53, 53, 53);">那么问题来了，一张1080P的彩色图像，按照上面的算法，图片的大小应该恒等于 3B</font><font style="color:rgb(53, 53, 53);">✖️</font><font style="color:rgb(53, 53, 53);">1920</font><font style="color:rgb(53, 53, 53);">✖️</font><font style="color:rgb(53, 53, 53);">1080 = 5.93MB。而实际使用感知是，相同分辨率，色彩越简单，图片越小。这是因为常用的图片格式会对图片进行压缩。不过图片的压缩算法不在本篇的讨论范围内。</font>

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746417802695-16986586-c58f-4766-8339-14ee134a3344.png)

读着不妨用opencv验证验证：

> 其实最好用png测试，因为jpg的有损压缩是不可逆的。但是还原出的位图也是1080p，问题不大~
>

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746418023006-5d3d6a5d-6f5f-47e6-9db2-5757c9a92533.png)

### 1.2 视频
![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746418366533-1512a87e-aa07-4298-b4f9-cceac639ba25.png)

#### 1.2.1 帧率
视频由一帧帧“连续”的图像组成。当然这里的连续，是相对肉眼的连续，实际上还是离散的。一秒内图像的数量，就是视频的帧率。

电影的帧率一般是24fps，再往上，增加的流畅度的收益很小，但是需要更高的硬件性能和带宽流量。所以帧率适度就好了。

#### 1.2.2 码率
<font style="color:rgb(53, 53, 53);">单用帧率还不足以衡量单位时间内视频的大小，因为每帧的图像大小也是不同的。可以使用码率来描述。</font>

<font style="color:rgb(53, 53, 53);">码率是指视频在单位时间内的数据量的大小，一般是 1 秒钟内的数据量，单位一般是 Kbps 或者 Mbps。</font>

<font style="color:rgb(53, 53, 53);">在视频传输中，码率这个参数尤其重要。</font>

#### 1.2.3 YUV
YUV和RGB一样，也是一种颜色空间，但更多用于视频领域。RGB可用于更精细的颜色控制，但是三个通道同等重要，不太好进行压缩。

<font style="color:rgb(53, 53, 53);">跟 RGB 图像中 R、G、B 三个通道都跟色彩信息相关这种特点不同，</font>**<font style="color:rgb(53, 53, 53);">YUV 图像将亮度信息 Y 与色彩信息 U、V 分离开来。Y 表示亮度，是图像的总体轮廓，称之为 Y 分量。U、V 表示色度，主要描绘图像的色彩等信息，分别称为 U 分量和 V 分量</font>**<font style="color:rgb(53, 53, 53);">。这样一张图像如果没有了色度信息 U、V，只剩下亮度 Y，则依旧是一张图像，只不过是一张黑白图像。</font>

<font style="color:rgb(53, 53, 53);">最初的YUV颜色空间的使用，是为了兼容黑白电视机。因为视频可能是彩色视频，黑白电视机只提取其中的Y分量就好了：</font>

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746420314533-d6c30f5e-1f27-4354-bff1-fe33a3a5dd02.png)

为什么只用UV两个分量就足以表示色度信息了呢？类比经纬度（2个坐标）能定位地球任意位置，无需第三个维度（海拔）也能表示平面位置。YUV 的 UV 色度分量同理，是色彩定位的“经纬度”。YUV可由RGB线性计算而来：

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746420516994-a9897c14-47a9-4e28-8eb9-1470313e30ba.png)

YUV允许对UV分量降采样，且降采样后人眼几乎看不出来（人眼对色度信息不敏感）。常用YUV 4:2:0，即每2✖️2像素块共用一个UV分量。降采后数据量降至一半。

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746421843832-2601885e-4b0e-4450-abc6-32d891bd23bd.png)

## 二、视频编码
视频中的图像一般是YUV格式，假设一个视频分辨率1080P、帧率25fps、时长2小时，那么它的大小等于1920✖️1080✖️25✖️1.5B✖️2✖️3600=521.4GB，显然太大了。这就需要对视频进行**编码压缩**。

<font style="color:rgb(53, 53, 53);">现在市面上常见的编码标准有 </font>**<font style="color:rgb(53, 53, 53);">H264、H265、VP8、VP9 和 AV1</font>**<font style="color:rgb(53, 53, 53);">。目前 H264 和 VP8 是最常用的编码标准，且两者的标准非常相似。H265 和 VP9 分别是他们的下一代编码标准，这两个标准也非常相似。AV1 是 VP9 的下一代编码标准。</font>

| **编码标准** | **压缩效率** | **编码速度** | **典型应用场景** | **适用原因** |
| :---: | :---: | :---: | :---: | :---: |
| **H.264** | 中等 | **快** | 视频会议、蓝光光盘、流媒体 | 兼容性极佳，硬件支持广泛，编码速度快，适合实时传输和通用播放 |
| **H.265** | 高 | **中等** | 4K流媒体、监控存储 | 比H.264节省50%码率，适合高分辨率视频，但需支付专利费 |
| **VP8** | 中等 | **快** | - WebRTC 实时通信（Discord）   - 早期Web视频（2015年前的YouTube） | 免版税，编码速度快，但效率已落后，逐渐被VP9取代 |
| **VP9** | 较高 | **较慢** | YouTube、WebM格式 | 免版税，效率接近H.265，Google生态强制推广，但对硬件加速支持有限 |
| **AV1** | **最高** | **最慢** | Netflix、8K流媒体 | 免版税且效率最高，长期替代H.265，但编码极慢，依赖新硬件（40系显卡） |


尝试使用Python进行视频编码。首先安装av库(ffmpeg的python绑定）：

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746430748743-c1341b63-2256-43d8-bc34-6a1da8ae258c.png)

使用h.264编码。其中container.add_stream指定编码和帧率，stream.width、stream.height指定分辨率，stream.pix_fmt设置编码器输出的像素格式。

```python
import av
import numpy as np

output_file = "output_h264.mp4"
width, height = 640, 480
fps = 30

container = av.open(output_file, mode="w")
stream = container.add_stream("h264", rate=fps)  # H.264 编码
stream.width = width
stream.height = height
stream.pix_fmt = "yuv420p"

for _ in range(100):
    # 创建蓝色背景（RGB格式：第三通道是蓝色）
    frame = np.zeros((height, width, 3), dtype=np.uint8)
    frame[:, :, 2] = 255  # 将蓝色通道设为最大值255
    
    # 转换为VideoFrame并编码
    video_frame = av.VideoFrame.from_ndarray(frame, format="rgb24")
    for packet in stream.encode(video_frame):
        container.mux(packet)

# 刷新缓冲区
for packet in stream.encode():
    container.mux(packet)

container.close()
print(f"H.264 视频（蓝色背景）已保存至 {output_file}")
```

使用vp8编码：

```python
import av
import numpy as np

output_file = "output_vp8.webm"
width, height = 640, 480
fps = 30

container = av.open(output_file, mode="w")
stream = container.add_stream("vp8", rate=fps)  # VP8 编码
stream.width = width
stream.height = height
stream.pix_fmt = "yuv420p"

for _ in range(100):
    frame = np.zeros((height, width, 3), dtype=np.uint8)
    frame[:, :, 2] = 255  # 蓝色通道设为255（RGB格式）
    video_frame = av.VideoFrame.from_ndarray(frame, format="rgb24")
    for packet in stream.encode(video_frame):
        container.mux(packet)

# 刷新缓冲区
for packet in stream.encode():
    container.mux(packet)

container.close()
print(f"VP8 视频已保存至 {output_file}")
```

输出蓝色背景的视频：

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746431251459-5c1dcd49-37f3-4ad5-9b92-590ac98d4ba5.png)

## 三、视频封装
视频封装和视频编码可以类比成箱子和内容的关系。封装格式称为Container，取决于文件拓展名。

之前的代码，如果output不加拓展名（封装格式），运行到`av.open`的时候就会报错。

```python
output_file = "output_h264_mov"
width, height = 640, 480
fps = 30

container = av.open(output_file, mode="w")
```

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746435886329-21b0b5bc-66a0-4ff2-bf33-63f487cc7f68.png)

封装格式适配的编码格式如下：

| **封装格式** | **最佳适配的视频编码** | **最佳适配的音频编码** |
| :---: | :---: | :---: |
| **MP4** | H.264、H.265 | AAC、AC-3 |
| **MKV** | H.265、AV1、VP9 | FLAC、DTS-HD、Opus |
| **AVI** | DivX/Xvid、MJPEG | MP3、PCM |
| **MOV** | ProRes、H.264 | AAC、ALAC |
| **WebM** | VP9、AV1 | Opus |
| **TS** | H.264、MPEG-2 | AAC、AC-3 |


如果指定的封装格式不支持设置的编码，会在`container.add_stream`的时候报错。

```python
output_file = "output_h264_mov.webm"
width, height = 640, 480
fps = 30

container = av.open(output_file, mode="w")
stream = container.add_stream("h264", rate=fps)  # H.264 编码
```

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746435993914-46338b61-d32a-4220-9ee7-36a12a76df2b.png)





