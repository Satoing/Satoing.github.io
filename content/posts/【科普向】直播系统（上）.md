---
title: "【科普向】直播系统（上）"
date: 2025-05-07
categories: ["科普向", "音视频开发"]
tags: ["音视频"]
---

上篇文章中简单学习了视频编码，有了一定的基础知识。这篇文章来来看看直播系统的架构。

本篇文章讨论的直播，指的是B站、抖音上的传统直播；而不是腾讯会议、视频通话这样的实时互动直播。后者主要考虑传输的实时性，通常将UDP作为底层协议；前者更注重画面质量和流畅度，对延迟的容忍性相对较高，通常使用TCP。

## 一、直播系统基础架构
### 1.1 实现分析
不妨先分析分析直播系统的需求。主播需要将自己的直播画面推送给直播间的观众，直播间的观众可以进行文字聊天和打赏。

主播将自己的直播画面推给观众，其实就是“采集->编码->推流 || -> || 拉流->解码->播放”的过程。

#### 1.1.1 主播侧
**主播侧要完成画面采集->编码->推流**。摄像头、麦克风采集到音视频数据后，由客户端进行编码。编码可以纯软件实现，由CPU进行编码；但是最好还是辅以GPU硬件加速，所以一般对主播的设备要求较高。最后将主播的音视频数据推送给服务器，这就是推流。主播侧的客户端，要实现的基本功能就是编码和推流，如哔哩哔哩直播姬。

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746547646694-fa82abaa-22e3-4f37-a679-3e6caa708944.png)

#### 1.1.2 观众侧
**观众侧完成直播流的拉取->解码->播放**。拉取到的直播流是经过编码压缩的，所以需要在本地解码，转换为YUV视频帧后，再由本地播放器播放。实际上，解码->播放的过程，目前已有很多开源的实现，如VLC，支持直接播放各种协议的直播流。通常把这些项目接入即可实现观众侧客户端。

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746548605617-d565330d-20ac-4eb1-af9f-2b9d3619f01a.png)

#### 1.1.3 业务侧
除了上面的音视频技术，直播系统还需要对房间进行维护，以及实现直播间的聊天和打赏等。这属于直播中业务系统的范畴，称为信令服务器。

在直播的场景下，用户量可以非常庞大。业务不仅需要考虑高并发，还需要考虑服务器转发消息的数量级。如A发送的聊天，直播间中所有观众都要看到，需要服务器主动往客户端推送。如果主播说扣1抽奖，直播间1W个观众都发了1，那么需要转发1W✖️1W条消息。这种场景如何避免消息洪泛，还是很有挑战性的，但是不在本篇的讨论范围内。

### 1.2 流程总结
![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746546414872-fe6551c0-9797-4aa3-a9b7-ffa44f858bd5.png)

1. 主播使用PC、手机都可以创建直播间。向信令服务器发送创建房间的请求，信令服务器返回推流的地址。图中1、3所示。
2. 主播将自己采集、编码的音视频数据推送到推流地址，如图中2、4所示。
3. 观众加入直播间。向信令服务器发送加入房间的请求，信令服务器返回直播流的地址。如图中5、6所示。
4. 观众在直播间中聊天、打赏，直接和信令服务器交互。

## 二、CDN
CDN即内容分发网络。将静态资源缓存到边缘节点，用户从最近的节点获取资源，减少物理距离带来的延迟。

CDN网络如下图所示。源节点是CDN网络的入口；主干节点通常用于缓存和跨运营商传输；边缘节点数量众多，一般部署到各地级市，用于解决“网络最后一公里”的问题。

![](https://img.jupng.top:7326/yuque/0/2025/png/2648742/1746625973079-041efea7-1e11-41cb-beb5-6f63b1421648.png)

在直播系统中，CDN的作用不仅仅是降低延迟，其分布式架构能有效解决直播中的一系列技术挑战：

1. 负载均衡：将观众的请求分散到多个边缘节点，避免源站过载。源站只需要推送一路流到CDN源节点，CDN内部分发到各个节点。
2. 带宽分摊：源站只需维持一路流，6Mbps基本能满足需求。
3. 多级缓存、故障切换：缓存热门直播流，即使CDN节点短暂网络波动，也能正常提供数据。若某个节点故障，CDN自动将观众迁移到健康节点。
4. 动态扩容：CDN节点可以非常方便地横向拓展，应对赛事等突发热门直播的场景。

## 三、HLS
HLS协议在直播和点播中都应用得非常广泛。它的核心是**将视频流分割成一系列短时长的ts文件，同时生成m3u8索引文件**，通过http协议传输，兼容性极强。

同时编码器可以将不同分辨率的视频流各自分片生成对应的m3u8文件，实现分辨率的切换。

### 3.1 生成HLS流
使用ffmpeg将test.mp4转换成HLS切片和索引：

```bash
ffmpeg -i test.mp4 -c copy -start_number 0 -hls_time 10 -hls_list_size 0 -hls_segment_filename test%03d.ts index.m3u
```

关键参数说明：

+ <font style="color:rgb(53, 53, 53);">-c copy，表示只是进行封装格式的转换，不需要转码。因为mp4和hls使用的都是H.264编码。</font>
+ <font style="color:rgb(53, 53, 53);">-hls_time，表示每个ts文件的最大时长，单位是秒。但是由于没有重新编码，所以这个时长并不准确。</font>
+ <font style="color:rgb(53, 53, 53);">-hls_segment_filename，表示指定ts文件的名称。</font>

### 3.2 m3u8格式分析
生成的m3u8及注释如下：

```latex
#EXTM3U
#EXT-X-VERSION:3 // 版本信息
#EXT-X-TARGETDURATION:10 // 每个分片的目标时长
#EXT-X-MEDIA-SEQUENCE:0 // 分片起始编号
#EXTINF:10.021300, // 第一个分片实际时长
test000.ts // 第一个分片文件
#EXTINF:9.979533, // 第二个分片实际时长
test001.ts // 第二个分片文件
...
#EXT-X-ENDLIST // 流结束标记
```

ts分片这里使用的是路径，一般使用url。可以使用web服务器（如Nginx）进行分发。

此外还有一些高级标签：

| 标签 | 作用 |
| --- | --- |
| `#EXT-X-STREAM-INF:BANDWIDTH=800000,RESOLUTION=1280x720` | 指定子流带宽（bps）、分辨率等参数，后跟多码率索引文件路径。实现多码率适配。 |
| `#EXT-X-MEDIA:TYPE=AUDIO` | 定义多音轨（如多语言） |
| `#EXT-X-PLAYLIST-TYPE:VOD` | 点播（VOD）流，表示完整文件；`EVENT` 表示直播流（无结束标记）。 |
| `#EXT-X-KEY:METHOD=AES-128` | 分片加密方式（如AES-128），需指定密钥URL和IV（初始化向量）。 |


示例1：多码率适配索引文件（MissAV中亦有记载）

```latex
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-STREAM-INF:BANDWIDTH=1500000,RESOLUTION=1280x720
high.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=800000,RESOLUTION=854x480
medium.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=400000,RESOLUTION=640x360
low.m3u8
```

示例2：加密索引文件

```latex
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:10
#EXT-X-KEY:METHOD=AES-128,URI="https://example.com/key.bin",IV=0x1234567890ABCDEF
#EXTINF:9.0,
video1.ts
#EXTINF:10.0,
video2.ts
```

m3u8下载器的原理，也就是从m3u8中逐个获取ts文件，最后拼接到一起。在限速的情况下，并发下载可以提高效率；缓存切片可以实现断点续传……这里可以操作的就很多了。

